/**
 * Investment Advisor Chat API Route (Enhanced)
 * 投资顾问对话 API 路由 (增强版)
 *
 * Implements multi-agent architecture with:
 * - Dynamic philosophy-based context loading
 * - Multiple analysis modes (quick, deep, debate, diagnose)
 * - Master investor perspectives
 * - Token budget management
 *
 * Reference: ai-hedge-fund, TradingAgents (UCLA)
 */

import { NextRequest, NextResponse } from "next/server";
import type { AdvisorContext, ChatMode } from "@/lib/advisor/agent/types";
import {
  buildAdvisorSystemPrompt,
  normalizeContext,
} from "@/lib/advisor/context-builder";
import {
  selectAgents,
  buildAgentPrompt,
} from "@/lib/advisor/agent/agent-orchestrator";
import { recommendAnalyst } from "@/lib/advisor/agent/analyst-agents";
import { INVESTMENT_ADVISOR_SYSTEM_PROMPT } from "@/lib/investment-context/conversation-templates";

// lurus-api configuration
// 在集群内部通过 Service 访问，外部通过 api.lurus.cn 访问
const LURUS_API_URL = process.env.LURUS_API_URL || "https://api.lurus.cn";
const LURUS_API_KEY =
  process.env.LURUS_API_KEY || "sk-gushenAIQuantTradingPlatform2026";

// Message interface for chat history
// 聊天历史的消息接口
interface ChatMessage {
  role: "system" | "user" | "assistant";
  content: string;
}

// Enhanced request body interface
// 增强的请求体接口
interface AdvisorChatRequest {
  message: string;
  history?: ChatMessage[];
  mode?: ChatMode;
  stream?: boolean;

  // New: Advisor context for philosophy-based analysis
  // 新增: 用于基于流派分析的顾问上下文
  advisorContext?: Partial<AdvisorContext>;

  // Legacy context (kept for backward compatibility)
  // 旧版上下文 (保持向后兼容)
  context?: {
    symbol?: string;
    symbolName?: string;
    sector?: string;
    timeframe?: string;
    riskTolerance?: string;
    marketData?: string;
  };
}

/**
 * Build system prompt based on advisor context or legacy context
 * 根据顾问上下文或旧版上下文构建系统提示词
 */
function buildSystemPrompt(
  advisorContext: Partial<AdvisorContext> | undefined,
  legacyContext: AdvisorChatRequest["context"],
  mode: ChatMode,
): string {
  // If advisor context is provided, use new dynamic context builder
  // 如果提供了顾问上下文，使用新的动态上下文构建器
  if (advisorContext) {
    const normalizedContext = normalizeContext(advisorContext);
    const built = buildAdvisorSystemPrompt(normalizedContext, mode, {
      stockSymbol: legacyContext?.symbol,
      stockName: legacyContext?.symbolName,
      marketData: legacyContext?.marketData,
    });

    console.log(
      `[Advisor API] Built dynamic context with ${built.includedSections.length} sections, ~${built.tokenBudget.total} tokens`,
    );

    return built.systemPrompt;
  }

  // Fallback to legacy system prompt
  // 回退到旧版系统提示词
  let prompt = INVESTMENT_ADVISOR_SYSTEM_PROMPT;

  if (legacyContext) {
    const contextAdditions: string[] = [];

    if (legacyContext.symbol) {
      contextAdditions.push(
        `当前用户关注的标的：${legacyContext.symbolName || legacyContext.symbol}`,
      );
    }
    if (legacyContext.sector) {
      contextAdditions.push(`当前关注的行业板块：${legacyContext.sector}`);
    }
    if (legacyContext.timeframe) {
      contextAdditions.push(`用户的投资时间框架：${legacyContext.timeframe}`);
    }
    if (legacyContext.riskTolerance) {
      contextAdditions.push(
        `用户的风险承受能力：${legacyContext.riskTolerance}`,
      );
    }
    if (legacyContext.marketData) {
      contextAdditions.push(`\n## 当前市场数据\n${legacyContext.marketData}`);
    }

    if (contextAdditions.length > 0) {
      prompt += `\n\n## 当前对话上下文\n${contextAdditions.join("\n")}`;
    }
  }

  return prompt;
}

/**
 * Get temperature and max tokens based on mode
 * 根据模式获取温度和最大 token 数
 */
function getModeConfig(mode: ChatMode): {
  temperature: number;
  maxTokens: number;
} {
  const configs: Record<ChatMode, { temperature: number; maxTokens: number }> =
    {
      quick: { temperature: 0.5, maxTokens: 1000 },
      deep: { temperature: 0.3, maxTokens: 4000 },
      debate: { temperature: 0.4, maxTokens: 3000 },
      diagnose: { temperature: 0.3, maxTokens: 3000 },
    };
  return configs[mode] || configs.deep;
}

/**
 * POST handler for investment advisor chat
 * 投资顾问对话 POST 处理器
 */
export async function POST(request: NextRequest) {
  try {
    const body: AdvisorChatRequest = await request.json();
    const {
      message,
      history = [],
      mode = "deep",
      stream = false,
      advisorContext,
      context,
    } = body;

    // Validate input
    // 验证输入
    if (!message || typeof message !== "string") {
      return NextResponse.json(
        { error: "Missing or invalid message" },
        { status: 400 },
      );
    }

    if (message.length > 5000) {
      return NextResponse.json(
        { error: "Message too long (max 5000 characters)" },
        { status: 400 },
      );
    }

    // Build system prompt with new or legacy context
    // 使用新或旧上下文构建系统提示词
    const systemPrompt = buildSystemPrompt(advisorContext, context, mode);

    // Build messages array
    // 构建消息数组
    const messages: ChatMessage[] = [
      { role: "system", content: systemPrompt },
      ...history.slice(-10), // Keep last 10 messages / 保留最近10条消息
      { role: "user", content: message },
    ];

    // Get mode-specific configuration
    // 获取模式特定配置
    const { temperature, maxTokens } = getModeConfig(mode);

    // Log request details
    // 记录请求详情
    const contextInfo = advisorContext
      ? `philosophy=${advisorContext.corePhilosophy}, methods=${advisorContext.analysisMethods?.join(",")}`
      : "legacy context";
    console.log(
      `[Advisor API] Processing ${mode} mode request (stream: ${stream}), ${contextInfo}, history: ${history.length} messages`,
    );
    const startTime = Date.now();

    // Call lurus-api (DeepSeek) for investment advice
    // 调用 lurus-api (DeepSeek) 获取投资建议
    const response = await fetch(`${LURUS_API_URL}/v1/chat/completions`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${LURUS_API_KEY}`,
      },
      body: JSON.stringify({
        model: "deepseek-chat",
        messages,
        temperature,
        max_tokens: maxTokens,
        stream,
      }),
      cache: "no-store",
    });

    if (!response.ok) {
      const errorText = await response.text().catch(() => "Unknown error");
      console.error("[Advisor API] LLM error:", response.status, errorText);
      return NextResponse.json(
        {
          error: "Failed to get advisor response",
          details: errorText,
          status: response.status,
        },
        { status: response.status },
      );
    }

    // Handle streaming response
    // 处理流式响应
    if (stream) {
      const responseTime = Date.now() - startTime;
      console.log(`[Advisor API] Streaming started in ${responseTime}ms`);

      // Create a TransformStream to process SSE data
      // 创建 TransformStream 处理 SSE 数据
      const encoder = new TextEncoder();
      const decoder = new TextDecoder();

      const transformStream = new TransformStream({
        transform(chunk, controller) {
          const text = decoder.decode(chunk, { stream: true });
          const lines = text.split("\n");

          for (const line of lines) {
            if (line.startsWith("data: ")) {
              const data = line.slice(6);

              // Check for stream end
              if (data === "[DONE]") {
                controller.enqueue(encoder.encode("data: [DONE]\n\n"));
                continue;
              }

              try {
                const parsed = JSON.parse(data);
                const content = parsed.choices?.[0]?.delta?.content || "";

                if (content) {
                  // Send content as SSE event
                  // 将内容作为 SSE 事件发送
                  const sseData = JSON.stringify({ content });
                  controller.enqueue(encoder.encode(`data: ${sseData}\n\n`));
                }
              } catch {
                // Skip invalid JSON
              }
            }
          }
        },
      });

      // Pipe the response through our transform
      // 通过我们的转换器管道响应
      const streamResponse = response.body?.pipeThrough(transformStream);

      return new Response(streamResponse, {
        headers: {
          "Content-Type": "text/event-stream",
          "Cache-Control": "no-cache",
          Connection: "keep-alive",
          "X-Response-Time": `${responseTime}ms`,
          "X-Mode": mode,
          "X-Context-Type": advisorContext ? "agentic" : "legacy",
        },
      });
    }

    // Handle non-streaming response
    // 处理非流式响应
    const responseTime = Date.now() - startTime;
    console.log(
      `[Advisor API] Response received in ${responseTime}ms, status: ${response.status}`,
    );

    const data = await response.json();
    const advisorResponse = data.choices?.[0]?.message?.content || "";

    if (!advisorResponse) {
      return NextResponse.json(
        { error: "Empty response from advisor" },
        { status: 500 },
      );
    }

    return NextResponse.json({
      success: true,
      response: advisorResponse,
      usage: data.usage,
      metadata: {
        mode,
        responseTime,
        model: data.model,
        contextType: advisorContext ? "agentic" : "legacy",
        philosophy: advisorContext?.corePhilosophy,
        masterAgent: advisorContext?.masterAgent,
      },
    });
  } catch (error) {
    console.error("[Advisor API] Error:", error);
    return NextResponse.json(
      { error: "Internal server error", message: String(error) },
      { status: 500 },
    );
  }
}

/**
 * GET handler - returns enhanced advisor capabilities
 * GET 处理器 - 返回增强的顾问能力
 */
export async function GET() {
  return NextResponse.json({
    name: "GuShen Investment Advisor",
    version: "2.0.0",
    framework: "Agentic Multi-Philosophy System",
    architecture: {
      agents: {
        analysts: ["Fundamentals", "Technical", "Sentiment", "Macro"],
        researchers: ["Bull", "Bear", "Moderator"],
        masters: ["Buffett", "Lynch", "Livermore", "Simons"],
      },
      philosophies: [
        "value",
        "growth",
        "trend",
        "quantitative",
        "index",
        "dividend",
        "momentum",
      ],
      analysisMethods: [
        "fundamental",
        "technical",
        "macro",
        "behavioral",
        "factor",
      ],
      tradingStyles: [
        "scalping",
        "day_trading",
        "swing",
        "position",
        "buy_hold",
      ],
      specialtyStrategies: [
        "san_dao_liu_shu",
        "canslim",
        "turtle",
        "cycle",
        "event_driven",
      ],
    },
    capabilities: [
      "Multi-agent analysis (多Agent分析)",
      "Philosophy-based context (流派上下文)",
      "Bull vs Bear debate (多空辩论)",
      "Master investor perspectives (大师视角)",
      "Dynamic token management (动态Token管理)",
      "Proactive alerts (主动预警)",
      "Individual stock analysis (个股分析)",
      "Sector rotation analysis (行业轮动分析)",
      "Market overview (市场概览)",
      "Risk assessment (风险评估)",
      "Position sizing suggestions (仓位建议)",
      "Entry/exit timing guidance (入场/出场时机指导)",
    ],
    modes: {
      quick: "Fast response for simple queries (~1500 tokens)",
      deep: "Comprehensive multi-dimensional analysis (~3000 tokens)",
      debate: "Bull vs Bear balanced analysis (~4000 tokens)",
      diagnose: "Portfolio multi-perspective diagnosis (~2500 tokens)",
    },
    status: "ready",
  });
}
